{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('pytorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1725e4b86ff19338a53d4ef169514e253a1b0f8de876b4a2efd8908323f84c9f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from os.path import join\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "tqdm.pandas()\n",
    "# nltk.download('all')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = 'train.csv'\n",
    "test_csv = 'test.csv'\n",
    "root = './'\n",
    "num_words = 15\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    300000.000000\n",
       "mean          6.842183\n",
       "std           2.827218\n",
       "min           1.000000\n",
       "25%           5.000000\n",
       "50%           6.000000\n",
       "75%           9.000000\n",
       "max          32.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "train_df.apply(lambda row: len(row['raw_address'].split()), axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    50000.000000\n",
       "mean         6.832440\n",
       "std          2.818035\n",
       "min          1.000000\n",
       "25%          5.000000\n",
       "50%          6.000000\n",
       "75%          9.000000\n",
       "max         25.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "test_df.apply(lambda row: len(row['raw_address'].split()), axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id                                        raw_address  \\\n",
       "0   0  jl kapuk timur delta sili iii lippo cika 11 a ...   \n",
       "1   1                                 aye, jati sampurna   \n",
       "2   2               setu siung 119 rt 5 1 13880 cipayung   \n",
       "3   3                               toko dita, kertosono   \n",
       "4   4                                      jl. orde baru   \n",
       "\n",
       "                                  POI/street        POI  \\\n",
       "0  /jl kapuk timur delta sili iii lippo cika              \n",
       "1                                          /              \n",
       "2                                     /siung              \n",
       "3                                 toko dita/  toko dita   \n",
       "4                             /jl. orde baru              \n",
       "\n",
       "                                     street  \n",
       "0  jl kapuk timur delta sili iii lippo cika  \n",
       "1                                            \n",
       "2                                     siung  \n",
       "3                                            \n",
       "4                             jl. orde baru  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>raw_address</th>\n      <th>POI/street</th>\n      <th>POI</th>\n      <th>street</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>jl kapuk timur delta sili iii lippo cika 11 a ...</td>\n      <td>/jl kapuk timur delta sili iii lippo cika</td>\n      <td></td>\n      <td>jl kapuk timur delta sili iii lippo cika</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>aye, jati sampurna</td>\n      <td>/</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>setu siung 119 rt 5 1 13880 cipayung</td>\n      <td>/siung</td>\n      <td></td>\n      <td>siung</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>toko dita, kertosono</td>\n      <td>toko dita/</td>\n      <td>toko dita</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>jl. orde baru</td>\n      <td>/jl. orde baru</td>\n      <td></td>\n      <td>jl. orde baru</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "train_df['POI'] = train_df.apply(lambda row: row['POI/street'].split('/')[0], axis=1)\n",
    "train_df['street'] = train_df.apply(lambda row: row['POI/street'].split('/')[-1], axis=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    300000.000000\n",
       "mean          1.143783\n",
       "std           1.579493\n",
       "min           0.000000\n",
       "25%           0.000000\n",
       "50%           0.000000\n",
       "75%           2.000000\n",
       "max          20.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "train_df.apply(lambda row: len(row['POI'].split()), axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    300000.000000\n",
       "mean          1.716237\n",
       "std           1.270470\n",
       "min           0.000000\n",
       "25%           1.000000\n",
       "50%           2.000000\n",
       "75%           3.000000\n",
       "max          15.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "train_df.apply(lambda row: len(row['street'].split()), axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_corpus = dict()\n",
    "poi_corpus = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for row in train_df.itertuples(index=False):\n",
    "    keys = ['_'.join(word_tokenize(row.POI)), '_'.join(word_tokenize(row.street))]\n",
    "    \n",
    "    if keys[0] in poi_corpus.keys():\n",
    "        poi_corpus[keys[0]] += 1\n",
    "    else:\n",
    "        poi_corpus[keys[0]] = 1\n",
    "\n",
    "    if keys[1] in street_corpus.keys():\n",
    "        street_corpus[keys[1]] += 1\n",
    "    else:\n",
    "        street_corpus[keys[1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DescribeResult(nobs=93412, minmax=(1, 178509), mean=3.21157881214405, variance=341133.5479799631, skewness=305.6149366133018, kurtosis=93401.32360912373)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "stats.describe(list(street_corpus.values()))\n",
    "stats.describe(list(poi_corpus.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(text, n):\n",
    "    n_grams = ngrams(word_tokenize(text), n)\n",
    "    return ['_'.join(grams) for grams in n_grams]\n",
    "\n",
    "def all_ngrams(text, num_words = 8):\n",
    "    result = {}\n",
    "    for i in range(1, num_words + 1):\n",
    "        result[i] = get_ngrams(text, i)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/jl.c suj 1'"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "def get_result(text: str, num_words = 8, thrs_poi = 0, thrs_street = 0):\n",
    "    result = {\n",
    "        'poi': None,\n",
    "        'street': None,\n",
    "    }\n",
    "    data = all_ngrams(text,num_words)\n",
    "\n",
    "    for k in range(num_words, 0, -1):\n",
    "        v = {\n",
    "            'poi': None,\n",
    "            'street': None,\n",
    "        }\n",
    "        data[k].sort(key=len, reverse=True) # sorts by descending length\n",
    "        for item in data[k]:\n",
    "            if item in poi_corpus.keys():\n",
    "                if poi_corpus[item] > thrs_poi:\n",
    "                    v['poi'] = detokenize(item)\n",
    "            if item in street_corpus:\n",
    "                if street_corpus[item] > thrs_street:\n",
    "                    v['street'] = detokenize(item)\n",
    "                    \n",
    "            for k in result.keys():\n",
    "                result[k] = result[k] if result[k] else v[k]\n",
    "        if (result['poi'] and result['street']):\n",
    "            break\n",
    "        \n",
    "    for k in result.keys():\n",
    "        result[k] = result[k] if result[k] else ''\n",
    "    return '/'.join(['', result['street']]) # hard code \n",
    "    # return '/'.join([result['poi'], result['street']])\n",
    "import string\n",
    "def detokenize(seq :str, split_token = '_'):\n",
    "    tokens = seq.split(split_token)\n",
    "    res = \"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in tokens]).strip()\n",
    "    return res \n",
    "get_result('jl.c suj 1, jogoyudan lumajang', num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10000/10000 [00:11<00:00, 858.05it/s]\n",
      "10000it [00:00, 965428.47it/s][0.3786, 0.5966, 0.5981, 0.2395]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def validate(df : pd.DataFrame, metric = \"accuracy\"):\n",
    "    df = df.copy()\n",
    "    total = len(df)\n",
    "    corrects = [0, 0, 0, 0]\n",
    "    preds = []\n",
    "    gt = []\n",
    "    \n",
    "    for row in tqdm(df.itertuples(index=False)):\n",
    "        poi, street = row.preds.split('/')\n",
    "        if (poi == row.POI) and (street == row.street):\n",
    "            corrects[0] += 1\n",
    "        if (poi == row.POI):\n",
    "            corrects[1] += 1\n",
    "        if (street == row.street):\n",
    "            corrects[2] += 1\n",
    "        else:\n",
    "            preds.append(street)\n",
    "            gt.append(row.street)\n",
    "\n",
    "        if ('' == row.street):\n",
    "            corrects[3] += 1\n",
    "    false_cases = pd.DataFrame({'gt':gt, 'preds':preds})\n",
    "    return false_cases, [c * 1.0 / total for c in corrects]\n",
    "\n",
    "# train_df['preds'] = train_df.progress_apply(lambda row: get_result(row['raw_address']), axis=1)\n",
    "sample_df = train_df.head(10000).copy()\n",
    "sample_df['preds'] = sample_df.progress_apply(lambda row: get_result(row['raw_address'],  num_words=num_words), axis=1)\n",
    "false_df, acc = validate(sample_df)\n",
    "print(acc) \n",
    "#[0.3721466666666667, 0.59503, 0.5920733333333333, 0.23381]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  gt           preds\n",
       "0           sampurna\n",
       "1               yaya\n",
       "2     kamp utan jaya\n",
       "3          kabupaten\n",
       "4             padang"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gt</th>\n      <th>preds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>sampurna</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>yaya</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>kamp utan jaya</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>kabupaten</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>padang</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "false_df.to_csv('false.csv',index=False)\n",
    "false_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 50000/50000 [00:58<00:00, 860.62it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df['preds'] = test_df.progress_apply(lambda row: get_result(row['raw_address'], num_words=num_words), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id':test_df['id'],\n",
    "    'POI/street':test_df['preds']\n",
    "    })\n",
    "\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spacy.lang.en import English\n",
    "# from spacy.matcher import PhraseMatcher\n",
    "\n",
    "# nlp = English()\n",
    "# matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "# patterns = [nlp.make_doc(name) for name in [\"Angela Merkel\", \"Barack Obama\"]]\n",
    "# matcher.add(\"Names\", patterns)\n",
    "\n",
    "# doc = nlp(\"angela merkel and us president barack Obama\")\n",
    "# for match_id, start, end in matcher(doc):\n",
    "#     print(\"Matched based on lowercase token text:\", doc[start:end])"
   ]
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('pytorch': conda)",
   "metadata": {
    "interpreter": {
     "hash": "1725e4b86ff19338a53d4ef169514e253a1b0f8de876b4a2efd8908323f84c9f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cahya/bert-base-indonesian-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"cahya/bert-base-indonesian-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "example = \"mah iv 403 margahayu rt 5 rw 16 bekasi timur\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['[CLS]', 'mah', 'iv', '40', '##3', 'marga', '##hay', '##u', 'rt', '5', 'rw', '16', 'bekasi', 'timur', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "output = tokenizer.encode(example)\n",
    "print(tokenizer.convert_ids_to_tokens(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\n",
    "    \"O\",       # Outside of a named entity\n",
    "    \"B-MISC\",  # Beginning of a miscellaneous entity right after another miscellaneous entity\n",
    "    \"I-MISC\",  # Miscellaneous entity\n",
    "    \"B-PER\",   # Beginning of a person's name right after another person's name\n",
    "    \"I-PER\",   # Person's name\n",
    "    \"B-ORG\",   # Beginning of an organisation right after another organisation\n",
    "    \"I-ORG\",   # Organisation\n",
    "    \"B-LOC\",   # Beginning of a location right after another location\n",
    "    \"I-LOC\"    # Location\n",
    "]\n",
    "\n",
    "print([(token, label_list[prediction]) for token, prediction in zip(tokens, predictions[0].tolist())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'word': 'mah',\n",
       "  'score': 0.47462132573127747,\n",
       "  'entity': 'B-LOC',\n",
       "  'index': 1,\n",
       "  'start': 0,\n",
       "  'end': 3},\n",
       " {'word': 'iv',\n",
       "  'score': 0.651638388633728,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 2,\n",
       "  'start': 4,\n",
       "  'end': 6},\n",
       " {'word': '40',\n",
       "  'score': 0.4350748360157013,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 3,\n",
       "  'start': 7,\n",
       "  'end': 9},\n",
       " {'word': '##3',\n",
       "  'score': 0.446559876203537,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 4,\n",
       "  'start': 9,\n",
       "  'end': 10},\n",
       " {'word': 'marga',\n",
       "  'score': 0.6634693741798401,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 5,\n",
       "  'start': 11,\n",
       "  'end': 16},\n",
       " {'word': '##hay',\n",
       "  'score': 0.8045898079872131,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 6,\n",
       "  'start': 16,\n",
       "  'end': 19},\n",
       " {'word': '##u',\n",
       "  'score': 0.6371545791625977,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 7,\n",
       "  'start': 19,\n",
       "  'end': 20},\n",
       " {'word': 'rt',\n",
       "  'score': 0.9035879373550415,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 8,\n",
       "  'start': 21,\n",
       "  'end': 23},\n",
       " {'word': '5',\n",
       "  'score': 0.9792085289955139,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 9,\n",
       "  'start': 24,\n",
       "  'end': 25},\n",
       " {'word': 'rw',\n",
       "  'score': 0.9676387906074524,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 10,\n",
       "  'start': 26,\n",
       "  'end': 28},\n",
       " {'word': '16',\n",
       "  'score': 0.9830562472343445,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 11,\n",
       "  'start': 29,\n",
       "  'end': 31},\n",
       " {'word': 'bekasi',\n",
       "  'score': 0.9352949261665344,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 12,\n",
       "  'start': 32,\n",
       "  'end': 38},\n",
       " {'word': 'timur',\n",
       "  'score': 0.8961782455444336,\n",
       "  'entity': 'I-LOC',\n",
       "  'index': 13,\n",
       "  'start': 39,\n",
       "  'end': 44}]"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "ner_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=\n[(0, 0)]\n"
     ]
    }
   ],
   "source": [
    "ner_results = nlp(example)\n",
    "l = 0 \n",
    "r = 0\n",
    "res = []\n",
    "for cur, x in enumerate(ner_results):\n",
    "    if x['entity'] == 'B-LOC':\n",
    "        res.append((l, r))\n",
    "        print('=')\n",
    "        l = cur\n",
    "        r = l + 1\n",
    "    elif x['entity'] == 'I-LOC':\n",
    "        r = r + 1\n",
    "    else:\n",
    "        res.append((l, r))\n",
    "        print('=')\n",
    "        l = r + 1\n",
    "        r = l\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of AlbertModel were not initialized from the model checkpoint at Wikidepia/indobert-lite-squad and are newly initialized: ['albert.pooler.weight', 'albert.pooler.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast, pipeline\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\n",
    "    'Wikidepia/indobert-lite-squad'\n",
    ")\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"Wikidepia/indobert-lite-squad\",\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "input = {\n",
    "    'context': \"asrama cpm, jl. lagoa kanal 2a rt. 01 rw. 16, kel. bawang\",\n",
    "    'question': \"jalan?\"\n",
    "}\n",
    "input = {\n",
    "    'context': \"asrama cpm, jl. lagoa kanal 2a rt. 01 rw. 16, kel. bawang\",\n",
    "    'question': \"minat?\"\n",
    "}\n",
    "res = qa_pipeline(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'asrama cpm'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "input['context'][res['start']:res['end']]"
   ]
  }
 ]
}